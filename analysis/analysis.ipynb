{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f41a7063",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import json\n",
    "from tld import get_fld\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2bdaa31d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Constants\n",
    "DATA_DIR = '../crawl_data'\n",
    "SRC_DIR = '../crawler_src'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0a20050",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Load the datasets\n",
    "os.chdir(DATA_DIR)\n",
    "\n",
    "# Get desktop json files\n",
    "data_json_desktop = glob.glob('*_desktop.json')\n",
    "\n",
    "# Get mobile json files\n",
    "data_json_mobile = glob.glob('*_mobile.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9997ec4f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def init_data_object():\n",
    "    return  {\n",
    "        # Per url data\n",
    "        'tranco_ranks': [],\n",
    "        'page_load_times': [],\n",
    "        'num_requests': [],\n",
    "        'distinct_third_parties': [],\n",
    "        'num_distinct_tracker_domains': [],\n",
    "        'num_distinct_tracker_entities': [],\n",
    "        \n",
    "        # Global data\n",
    "        'failures': {\n",
    "            'timeout_failures': 0,\n",
    "            'TLS_failures': 0,\n",
    "            'consent_failures': 0\n",
    "        },\n",
    "        'third_party_counts': {},\n",
    "        'third_party_tracker_counts': {},\n",
    "        'third_party_tracker_entities': {},\n",
    "        'uber_cookie': {\n",
    "            'request_hostname': '',\n",
    "            'website': '',\n",
    "            'num_cookies': 0,\n",
    "            'first_party': False\n",
    "        },\n",
    "        'longest_lifespan_cookies': [],\n",
    "        'canvas_fingerprints': [],\n",
    "        'tracker_redirect_combos': []\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1dfe9699",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def parse_stupid_blocklist_to_something_readable(file_path):\n",
    "    url_list = {}\n",
    "    \n",
    "    with open(file_path, encoding='utf-8') as blocklist_file:\n",
    "        blocklist = json.load(blocklist_file)\n",
    "        \n",
    "        for cat, entities in blocklist['categories'].items():\n",
    "            for entity_list in entities:\n",
    "                for entity, url_objects in entity_list.items():\n",
    "                    for url, aliases in url_objects.items():\n",
    "                        all_urls = [url]\n",
    "                        all_urls += aliases\n",
    "                        \n",
    "                        if entity not in url_list:\n",
    "                            url_list[entity] = []\n",
    "                            \n",
    "                        for u in all_urls:\n",
    "                            \n",
    "                            try:\n",
    "                                url_list[entity].append(get_fld(u, fix_protocol=True))\n",
    "                            except:\n",
    "                                pass\n",
    "                        \n",
    "                        url_list[entity] = list(set(url_list[entity]))\n",
    "    \n",
    "    return url_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4953277a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def create_stats_object(json_files):\n",
    "    data_object = init_data_object()\n",
    "    \n",
    "    for json_file in tqdm(json_files):\n",
    "        with open(json_file, 'r', encoding='utf-8') as data_file:\n",
    "            try:\n",
    "                data = json.load(data_file)\n",
    "            except:\n",
    "                print(f'Error opening json file: {json_file}, skipping')\n",
    "                data = {\"website_domain\": json_file.split('_')[0],\n",
    "                        \"rank\": -1,\n",
    "                        \"crawl_mode\": \"desktop\",\n",
    "                        \"post_pageload_url\": None,\n",
    "                        \"pageload_start_ts\": -1,\n",
    "                        \"pageload_end_ts\": -1,\n",
    "                        \"consent_status\": None,\n",
    "                        \"requests\": [],\n",
    "                        \"load_time\": -1,\n",
    "                        \"cookies\": -1,\n",
    "                        \"canvas_image_data\": None,\n",
    "                        \"failure_status\": {\n",
    "                            \"timeout\": True,\n",
    "                            \"TLS\": None,\n",
    "                            \"consent\": False\n",
    "                        }\n",
    "                    }\n",
    "                \n",
    "            # Append tranco rank\n",
    "            data_object['tranco_ranks'].append(int(data['rank']))\n",
    "            \n",
    "            # Updata failure counts\n",
    "            if data['failure_status']['timeout']:\n",
    "                data_object['failures']['timeout_failures'] += 1\n",
    "            if data['failure_status']['TLS'] != 'null':\n",
    "                data_object['failures']['TLS_failures'] += 1\n",
    "            if data['failure_status']['consent']:\n",
    "                data_object['failures']['consent_failures'] += 1\n",
    "                \n",
    "            # Only proceed if there is no timeout\n",
    "            if data['failure_status']['timeout']:\n",
    "                data_object['num_requests'].append(None)\n",
    "                data_object['page_load_times'].append(None)\n",
    "                data_object['distinct_third_parties'].append(None)\n",
    "                data_object['num_distinct_tracker_domains'].append(None)\n",
    "                data_object['num_distinct_tracker_entities'].append(None)\n",
    "                continue\n",
    "            \n",
    "            # Append page load time\n",
    "            data_object['page_load_times'].append(data['load_time'])\n",
    "            \n",
    "            # Append number of requests\n",
    "            data_object['num_requests'].append(len(data['requests']))\n",
    "            \n",
    "            # Append distinct third parties\n",
    "            get_fld_websocket = lambda u: get_fld(u[6:], fix_protocol=True) if u.startswith('wss://') \\\n",
    "                else get_fld(u, fix_protocol=True)\n",
    "            distinct_third_parties = set([ get_fld_websocket(d['request_url'])\n",
    "                                           for d in data['requests']\n",
    "                                         ])\n",
    "            distinct_third_parties.remove(get_fld(data['website_domain'], fix_protocol=True))\n",
    "            data_object['distinct_third_parties'].append(len(distinct_third_parties))\n",
    "            \n",
    "            # Append number of distinct tracker domains\n",
    "            tracker_dict = parse_stupid_blocklist_to_something_readable(SRC_DIR + '/disconnectmeblocklist.json')\n",
    "            distinct_tracker_domains = []\n",
    "            for third_party_domain in distinct_third_parties:\n",
    "                for _, domains in tracker_dict.items():\n",
    "                    if third_party_domain in domains:\n",
    "                        distinct_tracker_domains.append(third_party_domain)\n",
    "            data_object['num_distinct_tracker_domains'].append(len(distinct_tracker_domains))\n",
    "            \n",
    "            # Append number of distinct tracker entities/companies\n",
    "            distinct_tracker_entities = []\n",
    "            with open(SRC_DIR + '/domain_map.json', encoding='utf-8') as domain_map_json_file:\n",
    "                domain_map_json = json.load(domain_map_json_file)\n",
    "                \n",
    "                for tracker_domain in distinct_tracker_domains:\n",
    "                    if tracker_domain in domain_map_json.keys():\n",
    "                        distinct_tracker_entities.append(domain_map_json[tracker_domain]['entityName'])\n",
    "                    else:\n",
    "                        for tracker_entity, tracker_entity_domains in tracker_dict.items():\n",
    "                            if tracker_domain in tracker_entity_domains:\n",
    "                                distinct_tracker_entities.append(tracker_entity)\n",
    "                                break\n",
    "                \n",
    "            distinct_tracker_entities = set(distinct_tracker_entities)\n",
    "            data_object['num_distinct_tracker_entities'].append(len(distinct_tracker_entities))\n",
    "            \n",
    "            # Update third party reference counts\n",
    "            for party in distinct_third_parties:\n",
    "                if party in data_object['third_party_counts']:\n",
    "                    data_object['third_party_counts'][party] += 1\n",
    "                else:\n",
    "                    data_object['third_party_counts'][party] = 1\n",
    "            \n",
    "            # Update third party tracker counts\n",
    "            for tracker in distinct_tracker_domains:\n",
    "                if tracker in data_object['third_party_tracker_counts']:\n",
    "                    data_object['third_party_tracker_counts'][tracker] += 1\n",
    "                else:\n",
    "                    data_object['third_party_tracker_counts'][tracker] =1\n",
    "            \n",
    "            # Update third party tracker entities\n",
    "            for entity in distinct_tracker_entities:\n",
    "                if entity in data_object['third_party_tracker_entities']:\n",
    "                    data_object['third_party_tracker_entities'][entity] += 1\n",
    "                else:\n",
    "                    data_object['third_party_tracker_entities'][entity] =1\n",
    "                    \n",
    "            # Update the uber cookie\n",
    "            max_cookie_count = None\n",
    "            request_url = None\n",
    "            for request in data['requests']:\n",
    "                if 'cookie' not in request['request_headers']:\n",
    "                    continue\n",
    "                    \n",
    "                cookie_count = len(request['request_headers']['cookie'].split(';'))\n",
    "                if max_cookie_count is None or cookie_count > max_cookie_count:\n",
    "                    max_cookie_count = cookie_count\n",
    "                    request_url = request['request_url']\n",
    "            \n",
    "            if max_cookie_count is not None and \\\n",
    "               max_cookie_count > data_object['uber_cookie']['num_cookies']:\n",
    "                data_object['uber_cookie']['num_cookies'] = max_cookie_count\n",
    "                data_object['uber_cookie']['request_hostname'] = get_fld(request_url, fix_protocol=True)\n",
    "                data_object['uber_cookie']['website'] = data['website_domain']\n",
    "                data_object['uber_cookie']['first_party'] = data_object['uber_cookie']['request_hostname'] == \\\n",
    "                                                            data_object['uber_cookie']['website']\n",
    "                \n",
    "            # Get longest lasting cookies\n",
    "            cookie_ids = []\n",
    "            for request in data['requests']:\n",
    "                if 'cookie' not in request['request_headers']:\n",
    "                    continue\n",
    "                    \n",
    "                cookies = request['request_headers']['cookie'].split(';')\n",
    "                for cookie in cookies:\n",
    "                    cookie_ids.append(cookie.split('=')[0])\n",
    "            \n",
    "            all_cookies = []\n",
    "            for cookie in data['cookies']:\n",
    "                if cookie['name'] in cookie_ids:\n",
    "                    cookie_data = cookie.copy()\n",
    "                    cookie_data['size'] = len(cookie_data['value'])\n",
    "                    \n",
    "                    if 'sameSite' not in cookie_data:\n",
    "                        cookie_data['sameSite'] = None\n",
    "\n",
    "                    if 'expiry' not in cookie_data: # Cookies without expiry exist\n",
    "                        cookie_data['expiry'] = 999999999999999\n",
    "                    all_cookies.append(cookie_data)\n",
    "                    all_cookies.append(cookie_data)\n",
    "\n",
    "                sort_alg = lambda c: c['expiry']\n",
    "                all_cookies.sort(key=sort_alg, reverse=True)\n",
    "            data_object['longest_lifespan_cookies'] += all_cookies[:3]\n",
    "            data_object['longest_lifespan_cookies'].sort(key=sort_alg, reverse=True)\n",
    "            data_object['longest_lifespan_cookies'] = data_object['longest_lifespan_cookies'][:3]\n",
    "            \n",
    "            # HTTP redirect pairs for tracker domains\n",
    "            tracker_redirect_combos = []\n",
    "            for request in data['requests']:\n",
    "                if request['response_status_code'] >= 300 and \\\n",
    "                   request['response_status_code'] <= 399 and \\\n",
    "                   'location' in request['response_headers']:\n",
    "                    origin_domain = get_fld(request['request_url'], fix_protocol=True)\n",
    "                    if request['response_headers']['location'].startswith('http'): # TODO: verify this filters exactly all non-relative URLs\n",
    "                        redirect_domain = get_fld(request['response_headers']['location'], fix_protocol=True)\n",
    "                    else: # location can be relative URL\n",
    "                        redirect_domain = origin_domain\n",
    "                    if origin_domain != redirect_domain and \\\n",
    "                       (origin_domain in distinct_tracker_domains or \\\n",
    "                        redirect_domain in distinct_tracker_domains):\n",
    "                        tracker_redirect_combos.append((origin_domain, redirect_domain))\n",
    "            data_object['tracker_redirect_combos'] += list(set(tracker_redirect_combos))\n",
    "            \n",
    "            # Fingerprints\n",
    "            for fingerprint in data['canvas_image_data']:\n",
    "                fingerprint['website'] = get_fld(data['website_domain'], fix_protocol=True)\n",
    "            data_object['canvas_fingerprints'] += data['canvas_image_data']\n",
    "            \n",
    "    return data_object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f156626",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|████████████████▌                                            | 130/477 [00:07<00:19, 17.71it/s]\n"
     ]
    },
    {
     "ename": "TldDomainNotFound",
     "evalue": "Domain 118.89.204.198 didn't match any existing TLD name!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTldDomainNotFound\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Create the data objects\u001b[39;00m\n\u001b[1;32m      2\u001b[0m crawls \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m----> 3\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdesktop\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[43mcreate_stats_object\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_json_desktop\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmobile\u001b[39m\u001b[38;5;124m'\u001b[39m: create_stats_object(data_json_mobile)\n\u001b[1;32m      5\u001b[0m }\n",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36mcreate_stats_object\u001b[0;34m(json_files)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;66;03m# Append distinct third parties\u001b[39;00m\n\u001b[1;32m     55\u001b[0m get_fld_websocket \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m u: get_fld(u[\u001b[38;5;241m6\u001b[39m:], fix_protocol\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mif\u001b[39;00m u\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwss://\u001b[39m\u001b[38;5;124m'\u001b[39m) \\\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m get_fld(u, fix_protocol\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 57\u001b[0m distinct_third_parties \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m([ get_fld_websocket(d[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrequest_url\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     58\u001b[0m                                \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrequests\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     59\u001b[0m                              ])\n\u001b[1;32m     60\u001b[0m distinct_third_parties\u001b[38;5;241m.\u001b[39mremove(get_fld(data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwebsite_domain\u001b[39m\u001b[38;5;124m'\u001b[39m], fix_protocol\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m))\n\u001b[1;32m     61\u001b[0m data_object[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdistinct_third_parties\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mlen\u001b[39m(distinct_third_parties))\n",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;66;03m# Append distinct third parties\u001b[39;00m\n\u001b[1;32m     55\u001b[0m get_fld_websocket \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m u: get_fld(u[\u001b[38;5;241m6\u001b[39m:], fix_protocol\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mif\u001b[39;00m u\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwss://\u001b[39m\u001b[38;5;124m'\u001b[39m) \\\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m get_fld(u, fix_protocol\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 57\u001b[0m distinct_third_parties \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m([ \u001b[43mget_fld_websocket\u001b[49m\u001b[43m(\u001b[49m\u001b[43md\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrequest_url\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m                                \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrequests\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     59\u001b[0m                              ])\n\u001b[1;32m     60\u001b[0m distinct_third_parties\u001b[38;5;241m.\u001b[39mremove(get_fld(data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwebsite_domain\u001b[39m\u001b[38;5;124m'\u001b[39m], fix_protocol\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m))\n\u001b[1;32m     61\u001b[0m data_object[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdistinct_third_parties\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mlen\u001b[39m(distinct_third_parties))\n",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36mcreate_stats_object.<locals>.<lambda>\u001b[0;34m(u)\u001b[0m\n\u001b[1;32m     52\u001b[0m data_object[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_requests\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mlen\u001b[39m(data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrequests\u001b[39m\u001b[38;5;124m'\u001b[39m]))\n\u001b[1;32m     54\u001b[0m \u001b[38;5;66;03m# Append distinct third parties\u001b[39;00m\n\u001b[1;32m     55\u001b[0m get_fld_websocket \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m u: get_fld(u[\u001b[38;5;241m6\u001b[39m:], fix_protocol\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mif\u001b[39;00m u\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwss://\u001b[39m\u001b[38;5;124m'\u001b[39m) \\\n\u001b[0;32m---> 56\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[43mget_fld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfix_protocol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     57\u001b[0m distinct_third_parties \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m([ get_fld_websocket(d[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrequest_url\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     58\u001b[0m                                \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrequests\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     59\u001b[0m                              ])\n\u001b[1;32m     60\u001b[0m distinct_third_parties\u001b[38;5;241m.\u001b[39mremove(get_fld(data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwebsite_domain\u001b[39m\u001b[38;5;124m'\u001b[39m], fix_protocol\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m))\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tld/utils.py:438\u001b[0m, in \u001b[0;36mget_fld\u001b[0;34m(url, fail_silently, fix_protocol, search_public, search_private, parser_class, **kwargs)\u001b[0m\n\u001b[1;32m    431\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m parser_class:\n\u001b[1;32m    432\u001b[0m     parser_class \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    433\u001b[0m         MozillaTLDSourceParser\n\u001b[1;32m    434\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m search_private\n\u001b[1;32m    435\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m MozillaPublicOnlyTLDSourceParser\n\u001b[1;32m    436\u001b[0m     )\n\u001b[0;32m--> 438\u001b[0m domain_parts, non_zero_i, parsed_url \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_url\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    439\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    440\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfail_silently\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfail_silently\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    441\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfix_protocol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfix_protocol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    442\u001b[0m \u001b[43m    \u001b[49m\u001b[43msearch_public\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msearch_public\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    443\u001b[0m \u001b[43m    \u001b[49m\u001b[43msearch_private\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msearch_private\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    444\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparser_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparser_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    445\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    447\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m domain_parts \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    448\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tld/utils.py:381\u001b[0m, in \u001b[0;36mprocess_url\u001b[0;34m(url, fail_silently, fix_protocol, search_public, search_private, parser_class)\u001b[0m\n\u001b[1;32m    379\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, parsed_url\n\u001b[1;32m    380\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 381\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m TldDomainNotFound(domain_name\u001b[38;5;241m=\u001b[39mdomain_name)\n\u001b[1;32m    383\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m len_domain_parts \u001b[38;5;241m==\u001b[39m tld_length:\n\u001b[1;32m    384\u001b[0m     non_zero_i \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m  \u001b[38;5;66;03m# hostname = tld\u001b[39;00m\n",
      "\u001b[0;31mTldDomainNotFound\u001b[0m: Domain 118.89.204.198 didn't match any existing TLD name!"
     ]
    }
   ],
   "source": [
    "# Create the data objects\n",
    "crawls = {\n",
    "    'desktop': create_stats_object(data_json_desktop),\n",
    "    'mobile': create_stats_object(data_json_mobile)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7589984d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'crawls' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [8]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     df_input \u001b[38;5;241m=\u001b[39m {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m crawl_data\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m slice_keys}\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mDataFrame(data\u001b[38;5;241m=\u001b[39mdf_input)\n\u001b[0;32m----> 7\u001b[0m df_desktop \u001b[38;5;241m=\u001b[39m get_url_df(\u001b[43mcrawls\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdesktop\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      8\u001b[0m df_mobile \u001b[38;5;241m=\u001b[39m get_url_df(crawls[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmobile\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'crawls' is not defined"
     ]
    }
   ],
   "source": [
    "def get_url_df(crawl_data):\n",
    "    slice_keys = ['tranco_ranks', 'page_load_times', 'num_requests', 'distinct_third_parties',\n",
    "              'num_distinct_tracker_domains', 'num_distinct_tracker_entities']\n",
    "    df_input = {k: v for k, v in crawl_data.items() if k in slice_keys}\n",
    "    return pd.DataFrame(data=df_input)\n",
    "\n",
    "df_desktop = get_url_df(crawls['desktop'])\n",
    "df_mobile = get_url_df(crawls['mobile'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "794a1dc8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'crawls' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [9]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#1\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m desktop_failures \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPage load timeout\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[43mcrawls\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdesktop\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfailures\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtimeout_failures\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m      3\u001b[0m                     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTLS error\u001b[39m\u001b[38;5;124m'\u001b[39m: crawls[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdesktop\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfailures\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTLS_failures\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m      4\u001b[0m                     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mConsent click error\u001b[39m\u001b[38;5;124m'\u001b[39m: crawls[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdesktop\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfailures\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconsent_failures\u001b[39m\u001b[38;5;124m'\u001b[39m]}\n\u001b[1;32m      6\u001b[0m mobile_failures \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPage load timeout\u001b[39m\u001b[38;5;124m'\u001b[39m: crawls[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmobile\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfailures\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtimeout_failures\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m      7\u001b[0m                     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTLS error\u001b[39m\u001b[38;5;124m'\u001b[39m: crawls[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmobile\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfailures\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTLS_failures\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m      8\u001b[0m                     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mConsent click error\u001b[39m\u001b[38;5;124m'\u001b[39m: crawls[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmobile\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfailures\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconsent_failures\u001b[39m\u001b[38;5;124m'\u001b[39m]}\n\u001b[1;32m     10\u001b[0m failures_table \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCrawl-desktop\u001b[39m\u001b[38;5;124m'\u001b[39m: desktop_failures, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCrawl-mobile\u001b[39m\u001b[38;5;124m'\u001b[39m: mobile_failures})\n",
      "\u001b[0;31mNameError\u001b[0m: name 'crawls' is not defined"
     ]
    }
   ],
   "source": [
    "#1\n",
    "desktop_failures = {'Page load timeout': crawls['desktop']['failures']['timeout_failures'],\n",
    "                    'TLS error': crawls['desktop']['failures']['TLS_failures'],\n",
    "                    'Consent click error': crawls['desktop']['failures']['consent_failures']}\n",
    "\n",
    "mobile_failures = {'Page load timeout': crawls['mobile']['failures']['timeout_failures'],\n",
    "                    'TLS error': crawls['mobile']['failures']['TLS_failures'],\n",
    "                    'Consent click error': crawls['mobile']['failures']['consent_failures']}\n",
    "\n",
    "failures_table = pd.DataFrame({'Crawl-desktop': desktop_failures, 'Crawl-mobile': mobile_failures})\n",
    "failures_table.columns.name = 'Error type'\n",
    "print(failures_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c0d5fc",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#2\n",
    "def draw_boxplot(metric):\n",
    "    box_df = pd.DataFrame(df_desktop, columns=[metric])\n",
    "    box_df.rename(columns={metric:'Crawl-desktop'}, inplace=True)\n",
    "    box_df = box_df.join(df_mobile[metric])\n",
    "    box_df.rename(columns={metric:'Crawl-mobile'}, inplace=True)\n",
    "    return sns.boxplot(data=pd.DataFrame(data=box_df, columns=['Crawl-desktop','Crawl-mobile']))\n",
    "\n",
    "g_pageload = draw_boxplot('page_load_times')\n",
    "g_requests = draw_boxplot('num_requests')\n",
    "g_thirdparties = draw_boxplot('distinct_third_parties')\n",
    "g_trackdomains = draw_boxplot('num_distinct_tracker_domains')\n",
    "g_trackentities = draw_boxplot('num_distinct_tracker_entities')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed2532c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#4,5,6\n",
    "def print_ten_most_prev_websites_table(desktop_counts, mobile_counts):\n",
    "    table_desktop = pd.DataFrame({'Third-party desktop': desktop_counts.keys(), 'Nr of websites desktop': desktop_counts.values()}).sort_values(by=['Nr of websites desktop'],ascending=False).reset_index(drop=True)\n",
    "    table_mobile = pd.DataFrame({'Third-party mobile': mobile_counts.keys(), 'Nr of websites mobile': mobile_counts.values()}).sort_values(by=['Nr of websites mobile'],ascending=False).reset_index(drop=True)\n",
    "\n",
    "    table = pd.concat([table_desktop, table_mobile],axis=1)\n",
    "\n",
    "    # Some settings to make the table prettier\n",
    "    pd.set_option('display.precision', 0) # No decimals in count\n",
    "    pd.set_option('expand_frame_repr', False)\n",
    "    table.index += 1 # Start at index 1\n",
    "    columns=[('Crawl-desktop','Third-party'),('Crawl-desktop','Number of websites'),('Crawl-mobile','Third-party'),('Crawl-mobile','Number of websites') ]\n",
    "    table.columns=pd.MultiIndex.from_tuples(columns) # Add nested column names\n",
    "\n",
    "    #Only print the first 10 rows\n",
    "    print(table.head(10))\n",
    "\n",
    "print_ten_most_prev_websites_table(crawls['desktop']['third_party_counts'], crawls['mobile']['third_party_counts']) #4\n",
    "print()\n",
    "print_ten_most_prev_websites_table(crawls['desktop']['third_party_tracker_counts'], crawls['mobile']['third_party_tracker_counts'])#5\n",
    "print()\n",
    "print_ten_most_prev_websites_table(crawls['desktop']['third_party_tracker_entities'], crawls['mobile']['third_party_tracker_entities']) #6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b5ef0b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#7\n",
    "distinct_third_parties_desktop = pd.DataFrame( {'Tranco rank': crawls['desktop']['tranco_ranks'], 'Distinct third-party domains': crawls['desktop']['distinct_third_parties']})\n",
    "distinct_third_parties_mobile = pd.DataFrame( {'Tranco rank': crawls['mobile']['tranco_ranks'], 'Distinct third-party domains': crawls['mobile']['distinct_third_parties']})\n",
    "\n",
    "# TODO: remove NaN values\n",
    "\n",
    "sns.lmplot(x='Tranco rank', y='Distinct third-party domains', data=distinct_third_parties_desktop)\n",
    "sns.lmplot(x='Tranco rank', y='Distinct third-party domains', data=distinct_third_parties_mobile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b43d73",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#8\n",
    "distinct_trackers_desktop = pd.DataFrame( {'Tranco rank': crawls['desktop']['tranco_ranks'], 'Distinct tracker domains': crawls['desktop']['num_distinct_tracker_domains']})\n",
    "distinct_trackers_mobile = pd.DataFrame( {'Tranco rank': crawls['mobile']['tranco_ranks'], 'Distinct tracker domains': crawls['mobile']['num_distinct_tracker_domains']})\n",
    "\n",
    "# TODO: remove NaN values\n",
    "\n",
    "sns.lmplot(x='Tranco rank', y='Distinct tracker domains', data=distinct_trackers_desktop)\n",
    "sns.lmplot(x='Tranco rank', y='Distinct tracker domains', data=distinct_trackers_mobile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb86790a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#9\n",
    "data_9 = []\n",
    "for crawl, crawl_data in crawls.items():\n",
    "    data_9.append([crawl] + list(crawl_data['uber_cookie'].values()))\n",
    "    \n",
    "df_9 = pd.DataFrame(data_9)\n",
    "df_9.columns = ['crawl'] + list(crawls['desktop']['uber_cookie'].keys())\n",
    "df_9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce23abb",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#10\n",
    "data_10 = []\n",
    "for crawl, crawl_data in crawls.items():\n",
    "    for cookie in crawl_data['longest_lifespan_cookies']:\n",
    "        data_10.append([crawl] + list(cookie.values()))\n",
    "\n",
    "df_10 = pd.DataFrame(data_10)\n",
    "df_10.columns = ['crawl'] + list(crawls['desktop']['longest_lifespan_cookies'][0].keys())\n",
    "df_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c822e79",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#11\n",
    "data_11 = []\n",
    "for crawl, crawl_data in crawls.items():\n",
    "    for combo in crawl_data['tracker_redirect_combos']:\n",
    "        data_11.append([crawl, combo])\n",
    "        \n",
    "df_11 = pd.DataFrame(data_11)\n",
    "df_11.columns = ['crawl', 'combo']\n",
    "df_11.groupby(['crawl','combo'])['combo'] \\\n",
    "     .count() \\\n",
    "     .reset_index(name=\"count\") \\\n",
    "     .sort_values(['crawl', 'count'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3da273",
   "metadata": {},
   "outputs": [],
   "source": [
    "#12\n",
    "canvas_fingerprints = []\n",
    "for crawl, crawl_data in crawls.items():\n",
    "    for fingerprint in crawl_data['canvas_fingerprints']:\n",
    "        canvas_fingerprints.append([crawl,\n",
    "                                    fingerprint['website'],\n",
    "                                    fingerprint['fingerprint_script_resource_url'],\n",
    "                                    '<img src=\"' + DATA_DIR + '/' + fingerprint['canvas_fingerprint_image'] + '\" />'\n",
    "                                   ])\n",
    "df_canvas_fingerprints = pd.DataFrame(canvas_fingerprints)\n",
    "df_canvas_fingerprints.columns = ['Crawl', 'Website', 'Fingerprint script URL', 'Canvas image']\n",
    "df_canvas_fingerprints = df_canvas_fingerprints.to_html(escape=False)\n",
    "HTML(df_canvas_fingerprints)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
