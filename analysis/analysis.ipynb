{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import json\n",
    "from tld import get_fld\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from IPython.display import HTML"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Constants\n",
    "DATA_DIR = '../crawl_data'\n",
    "SRC_DIR = '../crawler_src'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Load the datasets\n",
    "os.chdir(DATA_DIR)\n",
    "\n",
    "# Get desktop json files\n",
    "data_json_desktop = glob.glob('*_desktop.json')\n",
    "\n",
    "# Get mobile json files\n",
    "data_json_mobile = glob.glob('*_mobile.json')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def init_data_object():\n",
    "    return  {\n",
    "        # Per url data\n",
    "        'tranco_ranks': [],\n",
    "        'page_load_times': [],\n",
    "        'num_requests': [],\n",
    "        'distinct_third_parties': [],\n",
    "        'num_distinct_tracker_domains': [],\n",
    "        'num_distinct_tracker_entities': [],\n",
    "        \n",
    "        # Global data\n",
    "        'failures': {\n",
    "            'timeout_failures': 0,\n",
    "            'TLS_failures': 0,\n",
    "            'consent_failures': 0\n",
    "        },\n",
    "        'third_party_counts': {},\n",
    "        'third_party_tracker_counts': {},\n",
    "        'third_party_tracker_entities': {},\n",
    "        'uber_cookie': {\n",
    "            'request_hostname': '',\n",
    "            'website': '',\n",
    "            'num_cookies': 0,\n",
    "            'first_party': False\n",
    "        },\n",
    "        'longest_lifespan_cookies': [],\n",
    "        'canvas_fingerprints': [],\n",
    "        'tracker_redirect_combos': []\n",
    "    }"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def parse_stupid_blocklist_to_something_readable(file_path):\n",
    "    url_list = {}\n",
    "    \n",
    "    with open(file_path, encoding='utf-8') as blocklist_file:\n",
    "        blocklist = json.load(blocklist_file)\n",
    "        \n",
    "        for cat, entities in blocklist['categories'].items():\n",
    "            for entity_list in entities:\n",
    "                for entity, url_objects in entity_list.items():\n",
    "                    for url, aliases in url_objects.items():\n",
    "                        all_urls = [url]\n",
    "                        all_urls += aliases\n",
    "                        \n",
    "                        if entity not in url_list:\n",
    "                            url_list[entity] = []\n",
    "                            \n",
    "                        for u in all_urls:\n",
    "                            \n",
    "                            try:\n",
    "                                url_list[entity].append(get_fld(u, fix_protocol=True))\n",
    "                            except:\n",
    "                                pass\n",
    "                        \n",
    "                        url_list[entity] = list(set(url_list[entity]))\n",
    "    \n",
    "    return url_list"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def create_stats_object(json_files):\n",
    "    data_object = init_data_object()\n",
    "    \n",
    "    for json_file in tqdm(json_files):\n",
    "        with open(json_file, 'r', encoding='utf-8') as data_file:\n",
    "            try:\n",
    "                data = json.load(data_file)\n",
    "            except:\n",
    "                print(f'Error opening json file: {json_file}, skipping')\n",
    "                data = {\"website_domain\": json_file.split('_')[0],\n",
    "                        \"rank\": -1,\n",
    "                        \"crawl_mode\": \"desktop\",\n",
    "                        \"post_pageload_url\": None,\n",
    "                        \"pageload_start_ts\": -1,\n",
    "                        \"pageload_end_ts\": -1,\n",
    "                        \"consent_status\": None,\n",
    "                        \"requests\": [],\n",
    "                        \"load_time\": -1,\n",
    "                        \"cookies\": -1,\n",
    "                        \"canvas_image_data\": None,\n",
    "                        \"failure_status\": {\n",
    "                            \"timeout\": True,\n",
    "                            \"TLS\": None,\n",
    "                            \"consent\": False\n",
    "                        }\n",
    "                    }\n",
    "                # TODO: whatsapp.com_desktop.json has no contents\n",
    "            # Append tranco rank\n",
    "            data_object['tranco_ranks'].append(data['rank'])\n",
    "            \n",
    "            # Updata failure counts\n",
    "            if data['failure_status']['timeout']:\n",
    "                data_object['failures']['timeout_failures'] += 1\n",
    "            if data['failure_status']['TLS'] != 'null':\n",
    "                data_object['failures']['TLS_failures'] += 1\n",
    "            if data['failure_status']['consent']:\n",
    "                data_object['failures']['consent_failures'] += 1\n",
    "                \n",
    "            # Only proceed if there is no timeout\n",
    "            if data['failure_status']['timeout']:\n",
    "                data_object['num_requests'].append(None)\n",
    "                data_object['page_load_times'].append(None)\n",
    "                data_object['distinct_third_parties'].append(None)\n",
    "                data_object['num_distinct_tracker_domains'].append(None)\n",
    "                data_object['num_distinct_tracker_entities'].append(None)\n",
    "                continue\n",
    "            \n",
    "            # Append page load time\n",
    "            data_object['page_load_times'].append(data['load_time'])\n",
    "            \n",
    "            # Append number of requests\n",
    "            data_object['num_requests'].append(len(data['requests']))\n",
    "            \n",
    "            # Append distinct third parties\n",
    "            get_fld_websocket = lambda u: get_fld(u[6:], fix_protocol=True) if u.startswith('wss://') \\\n",
    "                else get_fld(u, fix_protocol=True)\n",
    "            distinct_third_parties = set([ get_fld_websocket(d['request_url'])\n",
    "                                           for d in data['requests']\n",
    "                                         ])\n",
    "            distinct_third_parties.remove(get_fld(data['website_domain'], fix_protocol=True))\n",
    "            data_object['distinct_third_parties'].append(len(distinct_third_parties))\n",
    "            \n",
    "            # Append number of distinct tracker domains\n",
    "            tracker_dict = parse_stupid_blocklist_to_something_readable(SRC_DIR + '/disconnectmeblocklist.json')\n",
    "            distinct_tracker_domains = []\n",
    "            for third_party_domain in distinct_third_parties:\n",
    "                for _, domains in tracker_dict.items():\n",
    "                    if third_party_domain in domains:\n",
    "                        distinct_tracker_domains.append(third_party_domain)\n",
    "            data_object['num_distinct_tracker_domains'].append(len(distinct_tracker_domains))\n",
    "            \n",
    "            # Append number of distinct tracker entities/companies\n",
    "            distinct_tracker_entities = []\n",
    "            with open(SRC_DIR + '/domain_map.json', encoding='utf-8') as domain_map_json_file:\n",
    "                domain_map_json = json.load(domain_map_json_file)\n",
    "                \n",
    "                for third_tracker_domain in distinct_tracker_domains:\n",
    "                    if third_tracker_domain in domain_map_json.keys():\n",
    "                        distinct_tracker_entities.append(domain_map_json[third_tracker_domain]['entityName'])\n",
    "                    else:\n",
    "                        print('DOMAIN NOT FOUND IN ENTITY LIST, IMPLEMENT THIS WHEN YOU SEE THIS! DOMAIN OF DOOM: {}'\n",
    "                              .format(third_party_domain))\n",
    "                        # TODO: implement this\n",
    "                \n",
    "            distinct_tracker_entities = set(distinct_tracker_entities)\n",
    "            data_object['num_distinct_tracker_entities'].append(len(distinct_tracker_entities))\n",
    "            \n",
    "            # Update third party reference counts\n",
    "            for party in distinct_third_parties:\n",
    "                if party in data_object['third_party_counts']:\n",
    "                    data_object['third_party_counts'][party] += 1\n",
    "                else:\n",
    "                    data_object['third_party_counts'][party] = 1\n",
    "            \n",
    "            # Update third party tracker counts\n",
    "            for tracker in distinct_tracker_domains:\n",
    "                if tracker in data_object['third_party_tracker_counts']:\n",
    "                    data_object['third_party_tracker_counts'][tracker] += 1\n",
    "                else:\n",
    "                    data_object['third_party_tracker_counts'][tracker] =1\n",
    "            \n",
    "            # Update third party tracker entities\n",
    "            for entity in distinct_tracker_entities:\n",
    "                if entity in data_object['third_party_tracker_entities']:\n",
    "                    data_object['third_party_tracker_entities'][entity] += 1\n",
    "                else:\n",
    "                    data_object['third_party_tracker_entities'][entity] =1\n",
    "                    \n",
    "            # Update the uber cookie\n",
    "            max_cookie_count = None\n",
    "            request_url = None\n",
    "            for request in data['requests']:\n",
    "                if 'cookie' not in request['request_headers']:\n",
    "                    continue\n",
    "                    \n",
    "                cookie_count = len(request['request_headers']['cookie'].split(';'))\n",
    "                if max_cookie_count is None or cookie_count > max_cookie_count:\n",
    "                    max_cookie_count = cookie_count\n",
    "                    request_url = request['request_url']\n",
    "            \n",
    "            if max_cookie_count is not None and \\\n",
    "               max_cookie_count > data_object['uber_cookie']['num_cookies']:\n",
    "                data_object['uber_cookie']['num_cookies'] = max_cookie_count\n",
    "                data_object['uber_cookie']['request_hostname'] = get_fld(request_url, fix_protocol=True)\n",
    "                data_object['uber_cookie']['website'] = data['website_domain']\n",
    "                data_object['uber_cookie']['first_party'] = data_object['uber_cookie']['request_hostname'] == \\\n",
    "                                                            data_object['uber_cookie']['website']\n",
    "                \n",
    "            # Get longest lasting cookies\n",
    "            cookie_ids = []\n",
    "            for request in data['requests']:\n",
    "                if 'cookie' not in request['request_headers']:\n",
    "                    continue\n",
    "                    \n",
    "                cookies = request['request_headers']['cookie'].split(';')\n",
    "                for cookie in cookies:\n",
    "                    cookie_ids.append(cookie.split('=')[0])\n",
    "            \n",
    "            all_cookies = []\n",
    "            for cookie in data['cookies']:\n",
    "                if cookie['name'] in cookie_ids:\n",
    "                    cookie_data = cookie.copy()\n",
    "                    cookie_data['size'] = len(cookie_data['value'])\n",
    "                    \n",
    "                    if 'sameSite' not in cookie_data:\n",
    "                        cookie_data['sameSite'] = None\n",
    "\n",
    "                    if 'expiry' not in cookie_data: # Cookies without expiry exist\n",
    "                        cookie_data['expiry'] = 999999999999999\n",
    "                    all_cookies.append(cookie_data)\n",
    "                    all_cookies.append(cookie_data)\n",
    "\n",
    "                sort_alg = lambda c: c['expiry']\n",
    "                all_cookies.sort(key=sort_alg, reverse=True)\n",
    "            data_object['longest_lifespan_cookies'] += all_cookies[:3]\n",
    "            data_object['longest_lifespan_cookies'].sort(key=sort_alg, reverse=True)\n",
    "            data_object['longest_lifespan_cookies'] = data_object['longest_lifespan_cookies'][:3]\n",
    "            \n",
    "            # HTTP redirect pairs for tracker domains\n",
    "            tracker_redirect_combos = []\n",
    "            for request in data['requests']:\n",
    "                if request['response_status_code'] >= 300 and \\\n",
    "                   request['response_status_code'] <= 399 and \\\n",
    "                   'location' in request['response_headers']:\n",
    "                    origin_domain = get_fld(request['request_url'], fix_protocol=True)\n",
    "                    if request['response_headers']['location'].startswith('http'): # TODO: verify this filters exactly all non-relative URLs\n",
    "                        redirect_domain = get_fld(request['response_headers']['location'], fix_protocol=True)\n",
    "                    else: # location can be relative URL\n",
    "                        redirect_domain = origin_domain\n",
    "                    if origin_domain != redirect_domain and \\\n",
    "                       (origin_domain in distinct_tracker_domains or \\\n",
    "                        redirect_domain in distinct_tracker_domains):\n",
    "                        tracker_redirect_combos.append((origin_domain, redirect_domain))\n",
    "            data_object['tracker_redirect_combos'] = list(set(tracker_redirect_combos))\n",
    "            \n",
    "            # Fingerprints\n",
    "            for fingerprint in data['canvas_image_data']:\n",
    "                fingerprint['website'] = get_fld(data['website_domain'], fix_protocol=True)\n",
    "            data_object['canvas_fingerprints'] += data['canvas_image_data']\n",
    "            \n",
    "    return data_object"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Create the data objects\n",
    "crawls = {\n",
    "    'desktop': create_stats_object(data_json_desktop),\n",
    "    'mobile': create_stats_object(data_json_mobile)\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "data": {
      "text/plain": "    tranco_ranks  page_load_times  num_requests  distinct_third_parties  \\\n0             55              NaN           NaN                     NaN   \n1             80              NaN           NaN                     NaN   \n2            147                8           157                       2   \n3            135              NaN           NaN                     NaN   \n4             30                2            12                       0   \n..           ...              ...           ...                     ...   \n215          166                2             3                       1   \n216            2                7           164                       7   \n217          168              NaN           NaN                     NaN   \n218           26              NaN           NaN                     NaN   \n219           33                9           227                      37   \n\n     num_distinct_tracker_domains  num_distinct_tracker_entities  \n0                             NaN                            NaN  \n1                             NaN                            NaN  \n2                               0                              0  \n3                             NaN                            NaN  \n4                               0                              0  \n..                            ...                            ...  \n215                             1                              1  \n216                             4                              1  \n217                           NaN                            NaN  \n218                           NaN                            NaN  \n219                            29                             20  \n\n[220 rows x 6 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tranco_ranks</th>\n      <th>page_load_times</th>\n      <th>num_requests</th>\n      <th>distinct_third_parties</th>\n      <th>num_distinct_tracker_domains</th>\n      <th>num_distinct_tracker_entities</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>55</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>80</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>147</td>\n      <td>8</td>\n      <td>157</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>135</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>30</td>\n      <td>2</td>\n      <td>12</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>215</th>\n      <td>166</td>\n      <td>2</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>216</th>\n      <td>2</td>\n      <td>7</td>\n      <td>164</td>\n      <td>7</td>\n      <td>4</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>217</th>\n      <td>168</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>218</th>\n      <td>26</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>219</th>\n      <td>33</td>\n      <td>9</td>\n      <td>227</td>\n      <td>37</td>\n      <td>29</td>\n      <td>20</td>\n    </tr>\n  </tbody>\n</table>\n<p>220 rows Ã— 6 columns</p>\n</div>"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_url_df(crawl_data):\n",
    "    slice_keys = ['tranco_ranks', 'page_load_times', 'num_requests', 'distinct_third_parties',\n",
    "              'num_distinct_tracker_domains', 'num_distinct_tracker_entities']\n",
    "    df_input = {k: v for k, v in crawl_data.items() if k in slice_keys}\n",
    "    return pd.DataFrame(data=df_input)\n",
    "\n",
    "df_desktop = get_url_df(crawls['desktop'])\n",
    "df_mobile = get_url_df(crawls['mobile'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#2\n",
    "def draw_boxplot(metric):\n",
    "    box_df = pd.DataFrame(df_desktop, columns=[metric])\n",
    "    box_df.rename(columns={metric:'Crawl-desktop'}, inplace=True)\n",
    "    box_df = box_df.join(df_mobile[metric])\n",
    "    box_df.rename(columns={metric:'Crawl-mobile'}, inplace=True)\n",
    "    return sns.boxplot(data=pd.DataFrame(data=box_df, columns=['Crawl-desktop','Crawl-mobile']))\n",
    "\n",
    "g_pageload = draw_boxplot('page_load_times')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "g_requests = draw_boxplot('num_requests')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "g_thirdparties = draw_boxplot('distinct_third_parties')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "g_trackdomains = draw_boxplot('num_distinct_tracker_domains')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "g_trackentities = draw_boxplot('num_distinct_tracker_entities')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#1\n",
    "desktop_failures = {'Page load timeout': crawls['desktop']['failures']['timeout_failures'],\n",
    "                    'TLS error': crawls['desktop']['failures']['TLS_failures'],\n",
    "                    'Consent click error': crawls['desktop']['failures']['consent_failures']}\n",
    "\n",
    "mobile_failures = {'Page load timeout': crawls['mobile']['failures']['timeout_failures'],\n",
    "                    'TLS error': crawls['mobile']['failures']['TLS_failures'],\n",
    "                    'Consent click error': crawls['mobile']['failures']['consent_failures']}\n",
    "\n",
    "failures_table = pd.DataFrame({'Crawl-desktop': desktop_failures, 'Crawl-mobile': mobile_failures})\n",
    "failures_table.columns.name = 'Error type'\n",
    "print(failures_table)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Crawl-desktop                             Crawl-mobile                   \n",
      "             Third-party Number of websites           Third-party Number of websites\n",
      "1             google.com                 72            google.com                 75\n",
      "2        doubleclick.net                 68       doubleclick.net                 68\n",
      "3   google-analytics.com                 65  google-analytics.com                 64\n",
      "4   googletagmanager.com                 57  googletagmanager.com                 59\n",
      "5            gstatic.com                 54             google.nl                 53\n",
      "6              google.nl                 47           gstatic.com                 50\n",
      "7           facebook.com                 42          facebook.com                 40\n",
      "8           facebook.net                 35          facebook.net                 34\n",
      "9   fonts.googleapis.com                 30  googleadservices.com                 31\n",
      "10  googleadservices.com                 29  fonts.googleapis.com                 29\n",
      "\n",
      "            Crawl-desktop                              Crawl-mobile                   \n",
      "              Third-party Number of websites            Third-party Number of websites\n",
      "1              google.com                 72             google.com                 75\n",
      "2         doubleclick.net                 68        doubleclick.net                 68\n",
      "3    google-analytics.com                 65   google-analytics.com                 64\n",
      "4             gstatic.com                 54              google.nl                 53\n",
      "5               google.nl                 47            gstatic.com                 50\n",
      "6            facebook.com                 42           facebook.com                 40\n",
      "7            facebook.net                 35           facebook.net                 34\n",
      "8    googleadservices.com                 29   googleadservices.com                 31\n",
      "9                bing.com                 22            twitter.com                 22\n",
      "10  googlesyndication.com                 19  scorecardresearch.com                 21\n",
      "\n",
      "                Crawl-desktop                                  Crawl-mobile                   \n",
      "                  Third-party Number of websites                Third-party Number of websites\n",
      "1                  Google LLC                106                 Google LLC                104\n",
      "2              Facebook, Inc.                 45             Facebook, Inc.                 44\n",
      "3       Microsoft Corporation                 36      Microsoft Corporation                 35\n",
      "4                  Adobe Inc.                 19                 Adobe Inc.                 26\n",
      "5               comScore, Inc                 18              Twitter, Inc.                 23\n",
      "6   Amazon Technologies, Inc.                 17  Amazon Technologies, Inc.                 21\n",
      "7               Twitter, Inc.                 16              comScore, Inc                 21\n",
      "8          The Trade Desk Inc                 15         The Trade Desk Inc                 17\n",
      "9               Verizon Media                 12         Oracle Corporation                 16\n",
      "10            Pinterest, Inc.                 12                   LiveRamp                 15\n"
     ]
    }
   ],
   "source": [
    "#4,5,6\n",
    "\n",
    "def print_ten_most_prev_websites_table(desktop_counts, mobile_counts):\n",
    "    table_desktop = pd.DataFrame({'Third-party desktop': desktop_counts.keys(), 'Nr of websites desktop': desktop_counts.values()}).sort_values(by=['Nr of websites desktop'],ascending=False).reset_index(drop=True)\n",
    "    table_mobile = pd.DataFrame({'Third-party mobile': mobile_counts.keys(), 'Nr of websites mobile': mobile_counts.values()}).sort_values(by=['Nr of websites mobile'],ascending=False).reset_index(drop=True)\n",
    "\n",
    "    table = pd.concat([table_desktop, table_mobile],axis=1)\n",
    "\n",
    "    # Some settings to make the table prettier\n",
    "    pd.set_option('precision', 0) # No decimals in count\n",
    "    pd.set_option('expand_frame_repr', False)\n",
    "    table.index += 1 # Start at index 1\n",
    "    columns=[('Crawl-desktop','Third-party'),('Crawl-desktop','Number of websites'),('Crawl-mobile','Third-party'),('Crawl-mobile','Number of websites') ]\n",
    "    table.columns=pd.MultiIndex.from_tuples(columns) # Add nested column names\n",
    "\n",
    "    #Only print the first 10 rows\n",
    "    print(table.head(10))\n",
    "\n",
    "print_ten_most_prev_websites_table(crawls['desktop']['third_party_counts'], crawls['mobile']['third_party_counts']) #4\n",
    "print()\n",
    "print_ten_most_prev_websites_table(crawls['desktop']['third_party_tracker_counts'], crawls['mobile']['third_party_tracker_counts'])#5\n",
    "print()\n",
    "print_ten_most_prev_websites_table(crawls['desktop']['third_party_tracker_entities'], crawls['mobile']['third_party_tracker_entities']) #6"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#12\n",
    "canvas_fingerprints = []\n",
    "for crawl, crawl_data in crawls.items():\n",
    "    for fingerprint in crawl_data['canvas_fingerprints']:\n",
    "        canvas_fingerprints.append([crawl,\n",
    "                                    fingerprint['website'],\n",
    "                                    fingerprint['fingerprint_script_resource_url'],\n",
    "                                    '<img src=\"' + DATA_DIR + '/' + fingerprint['canvas_fingerprint_image'] + '\" />'\n",
    "                                   ])\n",
    "df_canvas_fingerprints = pd.DataFrame(canvas_fingerprints)\n",
    "df_canvas_fingerprints.columns = ['Crawl', 'Website', 'Fingerprint script URL', 'Canvas image']\n",
    "df_canvas_fingerprints = df_canvas_fingerprints.to_html(escape=False)\n",
    "HTML(df_canvas_fingerprints)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}